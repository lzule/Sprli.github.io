<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>李祖乐's blog</title><meta name="description" content="No Pain No Gain"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><script>var _hmt = _hmt || [];
(function() {
var hm = document.createElement("script");
hm.src = "//hm.baidu.com/hm.js?" + 'a2b0a21b8323843c2fcd318760ad1079';
var s = document.getElementsByTagName("script")[0];
s.parentNode.insertBefore(hm, s);
})();</script><!-- End Baidu Analytics --><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="李祖乐的博客" type="application/atom+xml">
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">李祖乐's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><span>归档 · 2023</span></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/Cmake/cmake_pic.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2023/05/26/Cmake_Study/"><img class="post-cover-img js-img-fadeIn" src="/images/Cmake/cmake_pic.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Cmake"><i class="tag post-item-tag">Cmake</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/05/26/Cmake_Study/">cmake学习记录</a></h2><time class="has-text-grey" datetime="2023-05-26T03:48:14.194Z">2023-05-26</time><p class="is-flex-grow-2 mt-2">
问题背景
这个问题是我在做海赛C2比赛编写部署自动打靶算法遇到的。先简单叙述一下起因，由于我们C2队伍使用的是Jetson Nano来识别靶心，进而实现自动打靶功能，于是算法识别这方面就由我来进展。在网上参考了一些部署方案。最终选择了使用Deepstream架构运行yolov5n的trt模型进行识别检测。但是由于我们的需求不仅是检测到靶心，还要将检测到的靶心的位置传递给下位机stm32，因此我需要在该架构中加入串口通信模块，实现该功能。由于Deepstream在国内的相关资料很少，故需要自己去了解并实现添加该模块到这个框架中。而且其代码基本都是C++代码，过程中要用到cmake等编译工具，故而接触到了cmake相关文件的编写与使用，并写下该篇博客对其进行记录。
一、cmake是什么
CMake是一个跨平台..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/05/26/Cmake_Study/">更多</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/build_hexo/hexo_pic.jpg" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2023/05/18/build_web/"><img class="post-cover-img js-img-fadeIn" src="/images/build_hexo/hexo_pic.jpg" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/05/18/build_web/">关于如何使用Hexo搭建自己的Github网站</a></h2><time class="has-text-grey" datetime="2023-05-18T15:52:40.130Z">2023-05-18</time><p class="is-flex-grow-2 mt-2">
一、下载Git与Nodejs
这里可以自行参考网上教程下载
二、使用hexo创建个人博客
2.1 创建Blog根目录

在本地创建一个文件夹，此文件夹将用来管理你的个人博客网站，如下图，我再F盘创建了一个git_blog文件夹

然后打开Git bash并输入cd F:/git/blog，如下图

然后再输入命令

npm install hexo-cli -g
hexo init
其中hexo init命令可能会失败，可以多试几次，最好挂梯子运行
全部输入完后，可以发现当前文件夹下多出一些文件夹和相关配置文件。


关于这些文件夹，可以先做一个简单的介绍：

node_modules: 依赖包
public：存放生成的页面
scaffolds：生成文章的一些模板
source：用来存放你的文章
them..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/05/18/build_web/">更多</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/Jetson/jetson_ruitai_pic.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2023/05/18/Jetson%20NX/"><img class="post-cover-img js-img-fadeIn" src="/images/Jetson/jetson_ruitai_pic.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Jetson"><i class="tag post-item-tag">Jetson</i></a><a href="/tags/Pytorch"><i class="tag post-item-tag">Pytorch</i></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><i class="tag post-item-tag">深度学习</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/05/18/Jetson%20NX/">关于Jetson的系统烧录与环境配置</a></h2><time class="has-text-grey" datetime="2023-05-18T08:07:49.654Z">2023-05-18</time><p class="is-flex-grow-2 mt-2">
一、准备

Ubuntu电脑 or 虚拟机（Ubuntu系统）
能够进行数据传输的Micro-USB数据线
显示屏 、HDMI转接线、键鼠

二、进行烧录（参考瑞泰教程）
2.1 系统软件包的下载
2.1.1 烧录所需文件集中在这两个文件夹中，在本部分我选择安装LT4 R32.7.1版本

2.1.2根据Jetson类型进行选择

2.1.3根据载板型号进行选择

2.1.4随便选择一个版本

2.1.5下载对应文件，其中rtso-6002对应位置即为载板型号

2.1.6选择对应版本的L4T文件

2.1.7下载相应文件

2.2 在PC端Ubuntu系统进行烧录环境准备
2.2.1 将上述文件拷贝至烧录主机同一目录下
2.2.2 解压 Linux Driver Package
$ tar -vxf J..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/05/18/Jetson%20NX/">更多</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/Pytorch2trt/tensorrt_pic.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2023/05/18/Torch2Trt/"><img class="post-cover-img js-img-fadeIn" src="/images/Pytorch2trt/tensorrt_pic.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><i class="tag post-item-tag">深度学习</i></a><a href="/tags/TensorRT"><i class="tag post-item-tag">TensorRT</i></a><a href="/tags/Onnx"><i class="tag post-item-tag">Onnx</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2023/05/18/Torch2Trt/">成功解决Pytorch模型转trt模型中得BatchNorm问题</a></h2><time class="has-text-grey" datetime="2023-05-18T06:12:16.513Z">2023-05-18</time><p class="is-flex-grow-2 mt-2">
问题背景
如果你想把你的模型投入到应用中或者是想提升模型的运行速度，除了对网络进行压缩、蒸馏外，最好的方法就是将模型转成tensor模型，使用tensorrt实现对网络的加速。但是当该模型的功能是图像增强或者是图像生成，并且模型中运用了大量的batchnorm2d函数，运用网上现成的方法会发现模型转成onnx以及trt后，模型的处理效果大幅下降，想解决此问题就可以详细往下看了：
我们的方法顺序是：pytorch模型先转成onnx模型，接着将onnx模型转成trt模型
一、pytorch to onnx
核心代码：
import torch
from torchvision.utils import save_image
import os
from nets.tiny_unet_2_channelxian..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2023/05/18/Torch2Trt/">更多</a></section></article></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><div style="position: sticky; top: 50px;"><main class="aside-card-container archives-widget is-in-archive-page"><h3>归档</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">三月 2024</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">二月 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/06/">六月 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a><span class="archive-list-count">4</span></li></ul></section></main></div></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/lzule"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><a title="rss" target="_blank" rel="noopener nofollow" href="/atom.xml"><i class="iconfont icon-rss"></i></a><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> 李祖乐 2024</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>